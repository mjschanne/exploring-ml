{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2806bc0b-3faa-439f-adc3-ef07176e989d",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks for MNIST Data Using PyTorch\n",
    "\n",
    "The \"Hello World\" of image classification is a convolutional neural network (CNN) applied to the MNIST digits dataset. A good way to see where this article is headed is to take a look at the screenshot of a demo program in **Figure 1**. The demo begins by loading a 1,000-item subset of the 60,000-item MNIST training data. Each MNIST image is a crude 28 x 28 pixel grayscale handwritten digit from \"0\" to \"9.\"\n",
    "\n",
    "Next, the demo program creates a CNN network that has two convolutional layers and three linear layers. The demo program trains the network for 50 epochs. An epoch is one pass through all training items. The loss/error slowly decreases from 230.0792 to 21.4261 which indicates that training is working.\n",
    "\n",
    "![Figure 1: CNN for MNIST Data Using PyTorch Demo Run](https://visualstudiomagazine.com/Articles/2022/02/15/~/media/ECG/visualstudiomagazine/Images/2022/02/fig_1_mnist_cnn_demo_run.ashx)\n",
    "__**Figure 1:** CNN for MNIST Data Using PyTorch Demo Run__\n",
    "\n",
    "After training, the demo program computes the classification accuracy of the model on the training data (96.60 percent = 966 out of 1,000 correct) and on a 100-item test dataset (96.00 percent = 96 out of 100 correct). Because the model accuracy on the test data is close to the accuracy on the training data, it appears that the model is not overfitted.\n",
    "\n",
    "Next, the trained model is used to predict the class label/digit for a new previously unseen dummy image. The dummy image is made of a horizontal bar, a vertical bar and a diagonal bar. The model predicts that the image is a \"four,\" which is what most humans would predict. The demo concludes by saving the trained model to file so that it can be used later without having to train it from scratch.\n",
    "\n",
    "This article assumes you have a basic familiarity with Python and the PyTorch neural network library. If you're new to PyTorch, you can get up to speed by reviewing the article **[\"Multi-Class Classification Using PyTorch: Defining a Network.\"](https://visualstudiomagazine.com/articles/2020/12/15/pytorch-network.aspx)**\n",
    "\n",
    "To run the demo program, you must have Python and PyTorch installed on your machine. The demo programs were developed on Windows 10 using the Anaconda 2020.02 64-bit distribution (which contains Python 3.7.6) and PyTorch version 1.10.0 for CPU installed via pip. You can find detailed step-by-step installation instructions for this configuration in my blog **[post](https://jamesmccaffrey.wordpress.com/2020/05/25/installing-pytorch-1-5-for-cpu-on-windows-10-with-anaconda-2020-02-for-python-3-7/).**\n",
    "\n",
    "The complete demo program source code is presented in this article. The source code is also available in the accompanying file download."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c96ec96-acb8-4bae-8c4c-3d20cbc644bf",
   "metadata": {},
   "source": [
    "## The MNIST Data\n",
    "\n",
    "The full MNIST (Modified National Institute of Standards and Technology) dataset has 60,000 training images and 10,000 test images. Each image is 28 x 28 pixels (784 values) and each pixel is a grayscale value between 0 and 255. **Figure 2** shows eight MNIST images.\n",
    "\n",
    "![Figure 2: Example MNIST Images](https://visualstudiomagazine.com/Articles/2022/02/15/~/media/ECG/visualstudiomagazine/Images/2022/02/fig_2_mnist_example_images.ashx)\n",
    "__**Figure 2:** Example MNIST Images__\n",
    "\n",
    "Most neural network libraries, including PyTorch, scikit and Keras, have built-in MNIST datasets. However, working with pre-built MNIST datasets has two big problems. First, a pre-built dataset is a black box that hides many details that are important if you ever want to work with other image data. Second, the pre-built datasets consist of all 60,000 training and 10,000 test images and those datasets are very difficult to work with because they're so large.\n",
    "\n",
    "The demo program assumes the existence of a tab-delimited text file of 1,000 training images where each image is stored on one line with the 784 pixel values first and the class \"0\" to \"9\" label last. The source MNIST data is stored in a proprietary binary format and converting the binary source files to text files is not trivial. An MNIST converter program is presented and explained in the Visual Studio Magazine article **[\"Preparing MNIST Image Data Text Files.\"](https://visualstudiomagazine.com/articles/2022/02/01/preparing-mnist-image-data-text-files.aspx)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a39cc8f-6b13-4cb9-83e6-a65fea9e707d",
   "metadata": {},
   "source": [
    "## The Demo Program\n",
    "\n",
    "The complete MNIST CNN demo program, with a few minor edits to save space, is presented in **Listing 1**. I prefer to indent my Python programs with two spaces rather than the more common four spaces. The backslash character is used for line continuation in Python.\n",
    "\n",
    "**Listing 1:** MNIST CNN Demo Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bf2d737-3008-44ba-9932-bd86465f85d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Begin MNIST with CNN demo \n",
      "\n",
      "Creating 1000-item train Dataset from text file \n",
      "\n",
      "Creating CNN network with 2 conv and 3 linear \n",
      "\n",
      "bat_size =  10 \n",
      "loss = CrossEntropyLoss()\n",
      "optimizer = SGD\n",
      "max_epochs =  50 \n",
      "lrn_rate = 0.005 \n",
      "\n",
      "Starting training\n",
      "epoch =    0   loss = 230.0792\n",
      "epoch =    5   loss = 227.4109\n",
      "epoch =   10   loss = 201.8226\n",
      "epoch =   15   loss = 86.4408\n",
      "epoch =   20   loss = 62.5790\n",
      "epoch =   25   loss = 49.5576\n",
      "epoch =   30   loss = 40.5146\n",
      "epoch =   35   loss = 31.5626\n",
      "epoch =   40   loss = 28.5285\n",
      "epoch =   45   loss = 21.5814\n",
      "Done \n",
      "\n",
      "Computing model accuracy\n",
      "Accuracy on training data = 0.9650\n",
      "Accuracy on test data = 0.9600\n",
      "\n",
      "Making prediction for fake image: \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted class is 'four'\n",
      "\n",
      "Saving trained model state\n",
      "\n",
      "End MNIST CNN demo \n"
     ]
    }
   ],
   "source": [
    "# mnist_cnn.py\n",
    "# PyTorch 1.10.0-CPU Anaconda3-2020.02  Python 3.7.6\n",
    "# Windows 10 \n",
    "\n",
    "# reads MNIST data from text file rather than using\n",
    "# built-in black box Dataset from torchvision\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch as T\n",
    "\n",
    "device = T.device('cpu')\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "class MNIST_Dataset(T.utils.data.Dataset):\n",
    "  # 784 tab-delim pixel values (0-255) then label (0-9)\n",
    "  def __init__(self, src_file):\n",
    "    all_xy = np.loadtxt(src_file, usecols=range(785),\n",
    "      delimiter=\"\\t\", comments=\"#\", dtype=np.float32)\n",
    "\n",
    "    tmp_x = all_xy[:, 0:784]  # all rows, cols [0,783]\n",
    "    tmp_x /= 255\n",
    "    tmp_x = tmp_x.reshape(-1, 1, 28, 28)  # bs, chnls, 28x28\n",
    "    tmp_y = all_xy[:, 784]    # 1-D required\n",
    "\n",
    "    self.x_data = \\\n",
    "      T.tensor(tmp_x, dtype=T.float32).to(device)\n",
    "    self.y_data = \\\n",
    "      T.tensor(tmp_y, dtype=T.int64).to(device) \n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.x_data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    lbl = self.y_data[idx]  # no use labels\n",
    "    pixels = self.x_data[idx] \n",
    "    return (pixels, lbl)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "class Net(T.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()  # pre Python 3.3 syntax\n",
    "\n",
    "    self.conv1 = T.nn.Conv2d(1, 32, 5)  # chnl-in, out, krnl\n",
    "    self.conv2 = T.nn.Conv2d(32, 64, 5)\n",
    "    self.fc1 = T.nn.Linear(1024, 512)   # [64*4*4, x]\n",
    "    self.fc2 = T.nn.Linear(512, 256)\n",
    "    self.fc3 = T.nn.Linear(256, 10)     # 10 classes\n",
    "    self.pool1 = T.nn.MaxPool2d(2, stride=2) # kernel, stride\n",
    "    self.pool2 = T.nn.MaxPool2d(2, stride=2)\n",
    "    self.drop1 = T.nn.Dropout(0.25)\n",
    "    self.drop2 = T.nn.Dropout(0.50)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    # convolution phase         # x is [bs, 1, 28, 28]\n",
    "    z = T.relu(self.conv1(x))   # Size([bs, 32, 24, 24])\n",
    "    z = self.pool1(z)           # Size([bs, 32, 12, 12])\n",
    "    z = self.drop1(z)\n",
    "    z = T.relu(self.conv2(z))   # Size([bs, 64, 8, 8])\n",
    "    z = self.pool2(z)           # Size([bs, 64, 4, 4])\n",
    "   \n",
    "    # neural network phase\n",
    "    z = z.reshape(-1, 1024)     # Size([bs, 1024])\n",
    "    z = T.relu(self.fc1(z))     # Size([bs, 512])\n",
    "    z = self.drop2(z)\n",
    "    z = T.relu(self.fc2(z))     # Size([bs, 256])\n",
    "    z = self.fc3(z)             # Size([bs, 10])\n",
    "    return z\n",
    "\n",
    "def accuracy(model, ds):\n",
    "  ldr = T.utils.data.DataLoader(ds,\n",
    "    batch_size=len(ds), shuffle=False)\n",
    "  n_correct = 0\n",
    "  for data in ldr:\n",
    "    (pixels, labels) = data\n",
    "    with T.no_grad():\n",
    "      oupts = model(pixels)\n",
    "    (_, predicteds) = T.max(oupts, 1)\n",
    "    n_correct += (predicteds == labels).sum().item()\n",
    "\n",
    "  acc = (n_correct * 1.0) / len(ds)\n",
    "  return acc\n",
    "\n",
    "def main():\n",
    "  # 0. setup\n",
    "  print(\"\\nBegin MNIST with CNN demo \")\n",
    "  np.random.seed(1)\n",
    "  T.manual_seed(1)\n",
    "\n",
    "  # 1. create Dataset\n",
    "  print(\"\\nCreating 1000-item train Dataset from text file \")\n",
    "  train_file = \"mnist_train_1000.txt\"\n",
    "  train_ds = MNIST_Dataset(train_file)\n",
    "\n",
    "  bat_size = 10\n",
    "  train_ldr = T.utils.data.DataLoader(train_ds,\n",
    "    batch_size=bat_size, shuffle=True)\n",
    "\n",
    "  # 2. create network\n",
    "  print(\"\\nCreating CNN network with 2 conv and 3 linear \")\n",
    "  net = Net().to(device)\n",
    "\n",
    "  # 3. train model\n",
    "  max_epochs = 50  # 100 gives better results\n",
    "  ep_log_interval = 5\n",
    "  lrn_rate = 0.005\n",
    "  \n",
    "  loss_func = T.nn.CrossEntropyLoss()  # does log-softmax()\n",
    "  optimizer = T.optim.SGD(net.parameters(), lr=lrn_rate)\n",
    "  \n",
    "  print(\"\\nbat_size = %3d \" % bat_size)\n",
    "  print(\"loss = \" + str(loss_func))\n",
    "  print(\"optimizer = SGD\")\n",
    "  print(\"max_epochs = %3d \" % max_epochs)\n",
    "  print(\"lrn_rate = %0.3f \" % lrn_rate)\n",
    "\n",
    "  print(\"\\nStarting training\")\n",
    "  net.train()  # set mode\n",
    "  for epoch in range(0, max_epochs):\n",
    "    ep_loss = 0  # for one full epoch\n",
    "    for (batch_idx, batch) in enumerate(train_ldr):\n",
    "      (X, y) = batch  # X = pixels, y = target labels\n",
    "      optimizer.zero_grad()\n",
    "      oupt = net(X)\n",
    "      loss_val = loss_func(oupt, y)  # a tensor\n",
    "      ep_loss += loss_val.item()  # accumulate\n",
    "      loss_val.backward()  # compute grads\n",
    "      optimizer.step()     # update weights\n",
    "    if epoch % ep_log_interval == 0:\n",
    "      print(\"epoch = %4d   loss = %0.4f\" % (epoch, ep_loss))\n",
    "  print(\"Done \") \n",
    "\n",
    "  # 4. evaluate model accuracy\n",
    "  print(\"\\nComputing model accuracy\")\n",
    "  net.eval()\n",
    "  acc_train = accuracy(net, train_ds)  # all at once\n",
    "  print(\"Accuracy on training data = %0.4f\" % acc_train)\n",
    "\n",
    "  test_file = \"mnist_test_100.txt\"\n",
    "  test_ds = MNIST_Dataset(test_file)\n",
    "  net.eval()\n",
    "  acc_test = accuracy(net, test_ds)  # all at once\n",
    "  print(\"Accuracy on test data = %0.4f\" % acc_test)\n",
    "\n",
    "  # 5. make a prediction\n",
    "  print(\"\\nMaking prediction for fake image: \")\n",
    "  x = np.zeros(shape=(28,28), dtype=np.float32)\n",
    "  for row in range(5,23):\n",
    "    x[row][9] = 180  # vertical line\n",
    "  for rc in range(9,19):\n",
    "    x[rc][rc] = 250  # diagonal\n",
    "  for col in range(5,15):  \n",
    "    x[14][col] = 200  # horizontal\n",
    "  x /= 255.0\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(x, cmap=plt.get_cmap('gray_r'))\n",
    "  plt.show()\n",
    "\n",
    "  digits = ['zero', 'one', 'two', 'three', 'four', 'five', \n",
    "    'six', 'seven', 'eight', 'nine' ]\n",
    "  x = x.reshape(1, 1, 28, 28)  # 1 image, 1 channel\n",
    "  x = T.tensor(x, dtype=T.float32).to(device)\n",
    "  with T.no_grad():\n",
    "    oupt = net(x)  # 10 logits like [[-0.12, 1.03, . . ]]\n",
    "  am = T.argmax(oupt) # 0 to 9\n",
    "  print(\"\\nPredicted class is \\'\" + digits[am] + \"\\'\")\n",
    "\n",
    "  # 6. save model\n",
    "  print(\"\\nSaving trained model state\")\n",
    "  fn = \"mnist_model.pt\"\n",
    "  T.save(net.state_dict(), fn)  \n",
    "\n",
    "  print(\"\\nEnd MNIST CNN demo \")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a9007b-1a36-422b-bfec-2deb20f3aaea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ebe444-03db-4796-b3d9-de9ebcc0cb7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
